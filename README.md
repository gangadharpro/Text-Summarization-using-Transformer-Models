# ðŸ§  Text Summarization Using Transformer Models

This project explores and compares multiple text summarization techniques â€” from traditional extractive methods to advanced transformer-based models â€” using the **CNN/DailyMail dataset**. It also includes a **Streamlit web app** for real-time summarization.

---

## ðŸ“Œ Project Overview

- **Goal**: Evaluate and compare summarization models for long-form news articles.
- **Dataset**: CNN/DailyMail news articles with human-written highlights.
- **Models Used**:
  - CNN-based Extractive Summarizer (TF-IDF + KMeans)
  - LSTM-Based Abstractive Summarizer (Base and Attention+GloVe)
  - Transformer-Based Summarizers (BART, T5)
- **Evaluation**: ROUGE Scores (ROUGE-1, ROUGE-2, ROUGE-L)

---

## ðŸš€ How to Run the Project

### 1. Clone the Repository
```bash
git clone https://github.com/gangadharpro/Text-Summarization-using-Transformer-Models.git
cd Text-Summarization-using-Transformer-Models
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run Streamlit App
```bash
streamlit run app.py
```

---

## ðŸ“Š ROUGE Score Summary

| Model                        | ROUGE-1 | ROUGE-2 | ROUGE-L |
|-----------------------------|---------|---------|---------|
| CNN Extractive              | ~0.15   | ~0.06   | ~0.11   |
| LSTM Base                   | 0.000   | 0.000   | 0.000   |
| LSTM Enhanced (GloVe+Attn)  | 0.000   | 0.000   | 0.000   |
| BART                        | **0.27**| **0.10**| **0.18**|
| T5                          | 0.25    | 0.09    | 0.17    |

---

## ðŸ“‚ Project Structure

```
ðŸ“¦ text-summarization-project/
â”œâ”€â”€ app.py
â”œâ”€â”€ organized_project_notebook.ipynb
â”œâ”€â”€ data_loader.py
â”œâ”€â”€ preprocessing.py
â”œâ”€â”€ cnn_extractive.py
â”œâ”€â”€ lstm_base.py
â”œâ”€â”€ lstm_enhanced.py
â”œâ”€â”€ transformer_models.py
â”œâ”€â”€ evaluation.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ”— Useful Links

- Dataset: [CNN/DailyMail on Hugging Face](https://huggingface.co/datasets/cnn_dailymail)
- BART Model: `facebook/bart-large-cnn`
- T5 Model: `t5-small`

---

## ðŸ“œ License

This project uses open-source datasets and pre-trained models. Please cite original sources where applicable.

